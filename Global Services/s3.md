#### Simple Storage Service
S3 is an object storage in the cloud. It provides secure and durable and highly scalable object storage. It allows you to store and retrieve any amount of data from anywhere on the web at a very low cost.
We can use bucket policies to make the entire bucket public rather than making the objects in the bucket public.
S3 is used to host static webpages.

#### S3 Standards
It is highly available and durable data is stored redundantly across devices in multiple AZs.
It is designed for frequently accessed data.
It is suitable for most workloads.
Uses cases includes 
- Websites
- Content distribution
- mobile and gaming applications
- big data analytics

#### Note
Dont install databases or OS on the S3. It is simply used for flat or static files.
S3 is also a unique namespace and the bucket name must be unique.

#### Version
versioning in s3 is used to so you can have multiple versions of your s3 object within s3.
older versions are then made private automatically.

#### Standard Infrequent Access
It is used for data that is used frequently but still requires rapid access but you have to pay to store and retrieve the data. It is great for long term usage and backups and act as data store for disaster recovery files.

#### Standard One zone Infrequent Access
It is the same as the infrequent access but the data is stored in one AZ instead of multiple AZ. It cost 20% less than the standard IA 

#### Glaciers
Glaciers are the cheap storage options that are used for archiving data that is very rarely accessed you pay every time the data is accessed. It has two options normal glacier retrieval time is form 1 minute to 12 hrs and the glacier deep archive has the retrieval time of 12 hrs

#### S3 intelligent tiering 
It automatically moves your data to the most cost effective tier based on how frequently the data is accessed through the use of machine learning 

#### Lifecycle Management
lifecycle management automates moving the object into different storage tiers to maximize cost effectiveness. You can use lifecycle management with #versions to move the previous versions into the different storage tiers.

#### S3 object lock
s3 object lock can be used to store object using the WORM model Write Once Read Many. It helps the objects from being deleted or modified for a certain amount of time. s3 object lock can be used to meet regulatory requirements or to add an extra layer of protection to the objects.

#### Governance Mode
In governance mode users cant overwrite or delete an object unless they have special permissions to do it.

#### Compliance Mode
In compliance mode the users can overwrite or alter the objects by an user or the root user for the duration of the retention period. 

#### Retention Period 
It protects the object version for a fixed amount of time. When you place a retention period on an object version amazon s3 stores a timestamp in the objects metadata to indicate when the retention period expires after the retention period expires the object version can be altered with unless the legal hold is also placed on the object.

#### Legal hold
Legal hold prevent the deletion of object lock or version from being deleted even if the retention period is also expired and legal hold can be removed only by user who have permissions. 

#### Glacier vault lock
S3 glacier vault lock allows you to control individual s3 glacier vaults with a vault lock policy. you can specify worm model in a glacier vault lock policy and lock the policy from future edits. Once locked the policy cannot be changed.

#### Encryption
There are three types of encryption in s3 
- In transit (using ssl/tls)
- at rest server side encryption(amz kms, amz sse)
- client side encryption
- enforce a bucket policy to deny the put request that dont have server side encryption

#### Optimize s3 performance
prefix are the folders inside the s3 buckets the more folders you have the better performance. The more prefixes you have the better performance you can have. If you are using SSE-KMS it has its limits.
There is also feature that is called as multipart uploads to increase to upload the file in chunks and it should be used for the files that are over 100 mbs and must be used for the files that are over 5 Gbs 
There is also a feature that can be used for downloads chunks of data from s3 it is called as s3 byte range fetches.

#### S3 Replication
You can replicate objects from one bucket to another and versioning must be enabled on both the source and the destination. objects in one bucket are not replicated automatically and delete markers are also not replicated by default.
buckets can either be in the same region or cross region.